{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6caf5bdb-7354-45d2-83d8-1460bdc96ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7aac6-f2bc-4bd4-b7d2-3c8d8ee94b54",
   "metadata": {},
   "source": [
    "#### Obtain and reshape training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f7f24d-4584-4c9f-af34-a8220ec99a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9daad6d-3fd1-464c-9ac8-29a5808d1e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:01<00:00, 6364361.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 236214.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 2155077.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 1060424.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define transform to convert data to tensors\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=download_data, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=download_data, transform=transform)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "x_train = train_dataset.data.numpy()\n",
    "y_train = train_dataset.targets.numpy()\n",
    "x_test = test_dataset.data.numpy()\n",
    "y_test = test_dataset.targets.numpy()\n",
    "\n",
    "# Reshape the data\n",
    "x_train_flatten = x_train.reshape(x_train.shape[0],-1).T / 255.  # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "x_test_flatten = x_test.reshape(x_test.shape[0],-1).T /255. # regularize data by 1/255\n",
    "y_train_flatten = y_train.reshape(y_train.T.shape[0],1).T\n",
    "y_test_flatten = y_test.reshape(y_test.T.shape[0],1).T "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a7834-04f4-4142-84cf-f55c0b2f55f9",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a55e214-2200-43fd-8c94-03dc2fa5611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z) :\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def deriv_ReLU(Z) :\n",
    "    return Z > 0\n",
    "    \n",
    "def softMAX(Z) :\n",
    "    exp_z = np.exp(Z - np.max(Z, axis=0, keepdims=True))  # Numerical stability\n",
    "    return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
    "\n",
    "def one_hot_(Y) :\n",
    "    Y = Y.flatten()  # Convert shape (1, m) to (m,)\n",
    "    one_hot_Y = np.zeros((10, Y.size))\n",
    "    one_hot_Y[Y, np.arange(Y.size)] = 1  # Fix indexing order\n",
    "    return one_hot_Y    \n",
    "\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "def get_accuracy(predictions,Y):\n",
    "    #print(predictions,Y)\n",
    "    return np.sum(predictions==Y)/Y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf026e-2c51-4631-8b3c-b348835a1d43",
   "metadata": {},
   "source": [
    "#### NN functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f5d8ec-2978-4016-9181-26d8f5068aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params() :\n",
    "    W1 = np.random.uniform (-0.15,0.15, (n_hidden_nodes, 784))\n",
    "    b1 = np.zeros((n_hidden_nodes, 1))\n",
    "    W2 = np.random.uniform (-0.15,0.15, (10, n_hidden_nodes))\n",
    "    b2 = np.zeros((10, 1))\n",
    "    # another way of initializing : W and b taken from a normal distribution\n",
    "    #W1 = np.random.randn(n_hidden_nodes,784) * 0.01\n",
    "    #b1 = np.random.randn(n_hidden_nodes,1)\n",
    "    #W2 = np.random.randn(10,n_hidden_nodes) * 0.01\n",
    "    #b2 = np.random.randn(10,1)\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def forward_prop(W1,b1,W2,b2,X) :\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softMAX(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, W2, X, Y) :\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot_(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha) :\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * np.reshape(db1,(n_hidden_nodes,1))\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * np.reshape(db2,(10,1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def gradient_descent(X, Y, X_, Y_, iterations, alpha):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    iterations+=1\n",
    "    for i in range(iterations) :\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        # test results:\n",
    "        _,  _,  _,  A2_= forward_prop(W1, b1, W2, b2, X_)\n",
    "        if i % 50 == 0 :\n",
    "            print(\"Itertation:\",i,\"Train Accuracy:\", get_accuracy(get_predictions(A2),Y))\n",
    "            print(\"Itertation:\",i,\"Test Accuracy:\", get_accuracy(get_predictions(A2_),Y_))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc72d03-b322-40bd-b6af-9779e3683390",
   "metadata": {},
   "source": [
    "#### Do actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8486375f-a416-4f77-9bf2-2069f83d8f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itertation: 0 Train Accuracy: 0.12498333333333334\n",
      "Itertation: 0 Test Accuracy: 0.2487\n",
      "Itertation: 50 Train Accuracy: 0.8055833333333333\n",
      "Itertation: 50 Test Accuracy: 0.8461\n",
      "Itertation: 100 Train Accuracy: 0.8979666666666667\n",
      "Itertation: 100 Test Accuracy: 0.9036\n",
      "Itertation: 150 Train Accuracy: 0.9086\n",
      "Itertation: 150 Test Accuracy: 0.9151\n",
      "Itertation: 200 Train Accuracy: 0.91675\n",
      "Itertation: 200 Test Accuracy: 0.9207\n"
     ]
    }
   ],
   "source": [
    "n_hidden_nodes = 100\n",
    "n_iterations = 200\n",
    "learning_rate = 0.3\n",
    "\n",
    "W1, b1, W2, b2 = gradient_descent(x_train_flatten, y_train_flatten, x_test_flatten, y_test_flatten, n_iterations, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86682cff-9a31-4d59-8d3c-f66a6a79facf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
