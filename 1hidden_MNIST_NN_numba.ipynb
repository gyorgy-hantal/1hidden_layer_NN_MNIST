{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf5bdb-7354-45d2-83d8-1460bdc96ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026fb83-da1c-4be5-b2c0-b423489dd192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7aac6-f2bc-4bd4-b7d2-3c8d8ee94b54",
   "metadata": {},
   "source": [
    "#### Obtain and reshape training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7f24d-4584-4c9f-af34-a8220ec99a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9daad6d-3fd1-464c-9ac8-29a5808d1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transform to convert data to tensors\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=download_data, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=download_data, transform=transform)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "x_train = train_dataset.data.numpy()\n",
    "y_train = train_dataset.targets.numpy()\n",
    "x_test = test_dataset.data.numpy()\n",
    "y_test = test_dataset.targets.numpy()\n",
    "\n",
    "# Reshape the data\n",
    "x_train_flatten = x_train.reshape(x_train.shape[0],-1).T / 255.  # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "x_test_flatten = x_test.reshape(x_test.shape[0],-1).T /255. # regularize data by 1/255\n",
    "y_train_flatten = y_train.reshape(y_train.T.shape[0],1).T\n",
    "y_test_flatten = y_test.reshape(y_test.T.shape[0],1).T "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a717b07-c10e-4305-8a6a-03e910a21604",
   "metadata": {},
   "source": [
    "#### CPU Functions on host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598ffa1-1ca4-4355-a8bf-1bb153f86604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params() :\n",
    "    W1 = np.random.uniform (-0.15,0.15, (n_hidden_nodes, 784))\n",
    "    b1 = np.zeros((n_hidden_nodes, 1))\n",
    "    W2 = np.random.uniform (-0.15,0.15, (10, n_hidden_nodes))\n",
    "    b2 = np.zeros((10, 1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# these perhaps need rewriting too:\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "def get_accuracy(predictions,Y):\n",
    "    #print(predictions,Y)\n",
    "    return np.sum(predictions==Y)/Y.size\n",
    "\n",
    "def one_hot_(Y) :\n",
    "    Y = Y.flatten()  # Convert shape (1, m) to (m,)\n",
    "    one_hot_Y = np.zeros((10, Y.size))\n",
    "    one_hot_Y[Y, np.arange(Y.size)] = 1  # Fix indexing order\n",
    "    return one_hot_Y    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce86917-3075-422c-b443-cbece676c01b",
   "metadata": {},
   "source": [
    "#### Helper device functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb0bbc-cd0b-4642-b2bf-5e8690dd9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def relu_gpu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def deriv_relu_gpu(x):\n",
    "    return 1.0 if x > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e87b7-3583-435e-b02b-dfa9d9dad654",
   "metadata": {},
   "source": [
    "#### Cuda kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334fc84-a0b2-41a5-b3bf-04b1f7c14907",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def relu_elementwise_gpu(Z, A):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < Z.shape[0] and j < Z.shape[1]:\n",
    "        A[i, j] = relu_gpu(Z[i, j])\n",
    "\n",
    "@cuda.jit\n",
    "def deriv_relu_elementwise_gpu(Z, dA):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < Z.shape[0] and j < Z.shape[1]:\n",
    "        dA[i, j] = deriv_relu_gpu(Z[i, j])\n",
    "\n",
    "@cuda.jit\n",
    "def matmul_elementwise_gpu(A, B, C):\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < A.shape[0] and col < B.shape[1]:\n",
    "        tmp = 0.0\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[row, k] * B[k, col]\n",
    "        C[row, col] = tmp\n",
    "\n",
    "@cuda.jit\n",
    "def softmax_elementwise_gpu(Z, A):\n",
    "    col = cuda.grid(1)\n",
    "    if col < Z.shape[1]:\n",
    "        max_val = -float('inf')\n",
    "        for i in range(Z.shape[0]):\n",
    "            if Z[i, col] > max_val:\n",
    "                max_val = Z[i, col]\n",
    "        sum_exp = 0.0\n",
    "        temp_exp = cuda.local.array(10, dtype=np.float32)\n",
    "        for i in range(Z.shape[0]):\n",
    "            temp_exp[i] = np.exp(Z[i, col] - max_val)\n",
    "            sum_exp += temp_exp[i]\n",
    "        for i in range(A.shape[0]):\n",
    "            A[i, col] = temp_exp[i] / sum_exp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bf026e-2c51-4631-8b3c-b348835a1d43",
   "metadata": {},
   "source": [
    "#### NN functions - to be rewritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a6bc0-dc2d-4e7e-8e7f-51321f879921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W1,b1,W2,b2,X) :\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softMAX(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, W2, X, Y) :\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot_(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha) :\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * np.reshape(db1,(n_hidden_nodes,1))\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * np.reshape(db2,(10,1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def gradient_descent(X, Y, X_, Y_, iterations, alpha):\n",
    "    iterations+=1\n",
    "    for i in range(iterations) :\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        # test results:\n",
    "        _,  _,  _,  A2_= forward_prop(W1, b1, W2, b2, X_)\n",
    "        if i % 50 == 0 :\n",
    "            print(\"Itertation:\",i,\"Train Accuracy:\", get_accuracy(get_predictions(A2),Y))\n",
    "            print(\"Itertation:\",i,\"Test Accuracy:\", get_accuracy(get_predictions(A2_),Y_))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc72d03-b322-40bd-b6af-9779e3683390",
   "metadata": {},
   "source": [
    "#### Do actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d19100-fb86-423a-b86c-19cfbef2b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_hidden_nodes = 100\n",
    "n_iterations = 200\n",
    "learning_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486375f-a416-4f77-9bf2-2069f83d8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2 = init_params()\n",
    "\n",
    "# move data to the GPU\n",
    "W1_d = cuda.to_device(W1)\n",
    "b1_d = cuda.to_device(b1)\n",
    "W2_d = cuda.to_device(W2)\n",
    "b2_d = cuda.to_device(b2)\n",
    "X_train_d = cuda.to_device(x_train_flatten)\n",
    "X_test_d = cuda.to_device(x_test_flatten)\n",
    "Y_train_d = cuda.to_device(one_hot_(y_train_flatten))\n",
    "Y_test_d = cuda.to_device(one_hot_(y_test_flatten))\n",
    "\n",
    "\n",
    "# run training...\n",
    "W1, b1, W2, b2 = gradient_descent...(X_train_d, Y_train_d, X_test_d, Y_test_d, n_iterations, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86682cff-9a31-4d59-8d3c-f66a6a79facf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
